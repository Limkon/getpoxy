name: Extract URLs from Search

on:
  workflow_dispatch:
  schedule:
    - cron: '0 11 */10 * *'

jobs:
  extract_urls:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v3
      with:
        python-version: '3.x'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install beautifulsoup4
        pip install requests

    - name: Extract URLs from Google Search
      id: search
      run: |
        python extract_urls.py
      env:
        SEARCH_QUERY: "订阅节点"

    - name: Save URLs to file
      run: |
        if [[ -s furls ]]; then
          echo "Search completed. Saving URLs to file."
          cat furls >> urls_temp
          mv urls_temp furls
        else
          echo "Search timed out or no URLs found. Generating empty furls file."
          touch furls
        fi

    - name: Commit and push changes
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add furls
        git commit -m "Add extracted URLs"
        git push
